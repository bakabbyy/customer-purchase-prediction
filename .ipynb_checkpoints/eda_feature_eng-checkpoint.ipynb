{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "# Exploratory Data Analysis & Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "<ul>\n",
    "<li><a href=\"#intro\">Introduction</a></li>\n",
    "<li><a href=\"#cleaning\">Data Cleaning</a></li>\n",
    "<li><a href=\"#feature\">Feature Engineering</a></li>\n",
    "<li><a href=\"#export\">Export Data</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='intro'></a>\n",
    "## Introduction\n",
    "This dataset consists of over 8.5M rows of consumer behavior data across an online cosmetics storefront. Every record contains a unique timestamp corresponding to an action the user took on the site; which includes viewing a product, adding a product to their cart, removing a product from the cart, and purchasing an item.  \n",
    "\n",
    "The goal for this project is to predict if a customer will make <font color='red'>[their first?]</font> purchase. To achieve this, all of the features will need to be created to aggregate individual user actions leading up to their purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "import psycopg2 as pg\n",
    "import pandas.io.sql as pd_sql\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set plot style for visualizations\n",
    "#plt.style.use('dark_background')\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up connection to postgres\n",
    "connection_args = {\n",
    "    'host': 'localhost',  \n",
    "    'dbname': 'events',    \n",
    "    'port': 5432          \n",
    "}\n",
    "connection = pg.connect(**connection_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# read in the dataset and label columns\n",
    "query = \"SELECT * FROM all_events;\"\n",
    "df = pd_sql.read_sql(query, connection)\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains 8.7M rows and 9 columns. The data represents individual actions taken by each user throughout each session."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleaning'></a>\n",
    "## Data Cleaning\n",
    "<ol>\n",
    "<li><a href=\"#cosmetics\">Non-cosmetics categories</a></li>\n",
    "<li><a href=\"#negative\">Negatively priced items</a></li>\n",
    "<li><a href=\"#remove\">Removed from cart</a></li>\n",
    "<li><a href=\"#first\">One-time visitors</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info(verbose=True, null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are quite a few null values in the `category_code` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.category_code.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cosmetics'></a>\n",
    "### 1. Non-cosmetics categories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-null columns appear to be non-cosmetic. These are assumed to be erroneous data and will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.category_code.isnull()]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='negative'></a>\n",
    "### 2. Negatively priced items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next let's look at the range in product pricing. Gauging propensity to purchase could potentially be pricing based, so it's good to get a sense of the pricing distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.price.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seem to be some items that are priced negatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.price < 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like each of these events correspond to a customer purchase. These could potentially be returned items. With that in mind, line items with negative purchases will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.price > 0]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='remove'></a>\n",
    "### 3. Removed from cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next I will look at event types to see what behaviors will be incorporated into the model in order to predict a future purchase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.event_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The different types of actions captured in the dataset include customer views of each product, adding items to cart, removing items from cart, and purchasing.  \n",
    "\n",
    "Because my objective is to find customer purchases, I must handle the event types in a way that will not be duplicative. Each action taken by the customer is captured in the data, therefore all rows where a customer purchased a product will also have a row within that same session where the customer added the item to their cart.  \n",
    "\n",
    "To account for this, counts of occurrences where a customer added an item to their cart should not include sessions where they made a purchase. With this in mind, removals from cart become duplicative and should be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df.event_type.isin(['view', 'cart', 'purchase'])]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='first'></a>\n",
    "### 4. One-time visitors\n",
    "One major source of variability in the data I may encounter when predicting future purchases is the presence of one-time visitors. One-time visitors may either buy or leave in their sole visit, which has the potential to throw off the model. Because I am looking to predict the first purchase a user will make, I will need more than one session per user to accurately predict future actions. As such, one-time visitors will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe of number of sessions per user, where the user logged more than one session\n",
    "query = \"\"\"\n",
    "SELECT user_id,\n",
    "       COUNT(user_session)\n",
    "FROM all_events\n",
    "GROUP BY 1\n",
    "HAVING COUNT(user_session) > 1;\n",
    "\"\"\"\n",
    "one_visit = pd_sql.read_sql(query, connection)\n",
    "one_visit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter original dataframe to include only the user IDs found in query\n",
    "df = df[df.user_id.isin(one_visit.user_id.values)]\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning Summary\n",
    "1. Remove extraneous product categories (non-cosmetics products)\n",
    "2. Remove negatively priced items\n",
    "3. Remove rows with `remove_from_cart`\n",
    "4. Filter out one-time users"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "<a id='feature'></a>\n",
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Target\n",
    "The target I am aiming to predict from this dataset is if a customer will make a purchase. The first step is to create a column that turns the \"purchase\" event into a binary classifier. From there, I can begin engineering other features to predict the event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create target column with binary classifier\n",
    "df['purchased'] = np.where(df['event_type'] == 'purchase', 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This approach will use features that are \"user-centric,\" meaning each line item will hold values for unique users. Each feature will contain roll-ups of that user's activity throughout the time period in which the data was captured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# group the original dataframe by user\n",
    "by_user = df.groupby('user_id', as_index=False).purchased.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a column to hold the total number of purchases per user\n",
    "# change the 'purchased' column to a binary classification\n",
    "by_user['num_purchases'] = by_user['purchased']\n",
    "by_user['purchased'] = (by_user['purchased'] >= 1).astype(int)\n",
    "by_user.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize feature classes to assess if there is imbalance\n",
    "by_user.purchased.value_counts().plot(kind='bar')\n",
    "plt.title('Target Classes');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoa. The result set is highly skewed with more users that have not purchased, which is in line with what I'd expect for e-commerce data within this window. I will have to take this into account when testing classification methods by stratifying the prediction and over/undersampling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recency, Frequency, Monetary Value\n",
    "Recency, frequency, and monetary value, commonly known as RFM, is a widely used metric in marketing analytics. This metric aims to group individual users into user segments, or cohorts, based on three factors:\n",
    "1. **Recency** - The last time the user made a purchase in the store. Since I am aiming to gauge future purchases based on behavior, I am adjusting this metric to reflect the last time the user made an action on the site. This value is represented as the number of days between the current date and the date of the last user action.\n",
    "2. **Frequency** - How many times the user made a purchase in a given window. Again, I will adjust this metric to include the number of actions taken rather than the number of purchases to better predict future purchases based on all behavior. \n",
    "3. **Monetary value** - The total dollar amount of all purchases made by the user. Similar to the other components, the typical RFM calculation will not work here, as we do not know whether the customer has made a purchase or not. To account for this, this value will measure the total value of products the customer has interacted with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run sql query that calculates RFM scores and create dataframe\n",
    "query = \"\"\"\n",
    "WITH rfm_raw AS (\n",
    "    SELECT user_id,\n",
    "           EXTRACT(DAY FROM CURRENT_DATE - MAX(event_time)) AS recency,\n",
    "           COUNT(DISTINCT user_session) AS frequency,\n",
    "           SUM(CASE WHEN event_type != 'purchase' THEN price END) AS monetary_value\n",
    "    FROM all_events\n",
    "    GROUP BY 1\n",
    "),\n",
    "rfm_scores AS (\n",
    "    SELECT rfm_raw.user_id,\n",
    "           NTILE(5) OVER(ORDER BY recency DESC) AS r,\n",
    "           NTILE(5) OVER(ORDER BY frequency DESC) AS f,\n",
    "           NTILE(5) OVER(ORDER BY monetary_value DESC) AS m\n",
    "    FROM all_events\n",
    "    JOIN rfm_raw\n",
    "    ON all_events.user_id = rfm_raw.user_id\n",
    ")\n",
    "\n",
    "SELECT DISTINCT user_id,\n",
    "       CONCAT(r, f, m) AS rfm_score\n",
    "FROM rfm_scores;\n",
    "\"\"\"\n",
    "rfm = pd_sql.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc-hr-collapsed": false
   },
   "source": [
    "### Actions per user\n",
    "Calculate the number of each unique action per user; purchases, product views, adds to cart, and removals from cart. These will all be separate features. Total number of purchases was already created when grouping by user, so this step will focus on creating features to quantify the other types of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "SELECT user_id,\n",
    "       SUM(CASE WHEN event_type = 'purchase' THEN 1 ELSE 0 END) AS num_purchases,\n",
    "       SUM(CASE WHEN event_type = 'view' THEN 1 ELSE 0 END) AS num_views,\n",
    "       SUM(CASE WHEN event_type = 'cart' THEN 1 ELSE 0 END) AS adds_to_cart,\n",
    "       SUM(CASE WHEN event_type = 'remove_from_cart' THEN 1 ELSE 0 END) AS removals_from_cart\n",
    "FROM all_events\n",
    "GROUP BY 1;\n",
    "\"\"\"\n",
    "actions = pd_sql.read_sql(query, connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='export'></a>\n",
    "## Export Data\n",
    "Merge dataframes created with new features to the original, grouped dataframe. Export the resulting dataframe as the dataset to run classification models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge rfm scores onto grouped dataframe\n",
    "users = by_user.merge(rfm, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop extra 'num_purchases' column from actions dataframe\n",
    "actions = actions.drop('num_purchases', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge user actions data\n",
    "users = users.merge(actions, on='user_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>Drop other num_purchases column for model, but may want to include this again at some point...?</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users = users.drop('num_purchases', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe to pickle file to easily import in modeling notebook\n",
    "with open('users.pickle', 'wb') as outfile:\n",
    "    pickle.dump(users, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'><h1>Additional features</h1></font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to cart rate\n",
    "Calculate the number of each unique action per user; purchases, product views, adds to cart, and removals from cart. These will all be separate features. Total number of purchases was already created when grouping by user, so this step will focus on creating features to quantify the other types of action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_copy = users.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
